{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb37e65",
   "metadata": {},
   "source": [
    "# Rossmann Sales Forecasting — Time Series Modeling\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Rossmann operates over 3,000 drugstores across Europe. Due to the short shelf life of many pharmaceutical products, it's essential to forecast daily sales accurately.\n",
    "\n",
    "Currently, store managers manually forecast daily sales for the next six weeks. To improve consistency and accuracy, we're tasked with building a **data-driven time-series model** to automate this process.\n",
    "\n",
    "---\n",
    "\n",
    "### Objective:\n",
    "\n",
    "Build a robust **time-series forecasting pipeline** to predict **daily sales for the next 6 weeks**, for **9 key Rossmann stores** using:\n",
    "- Time-series decomposition\n",
    "- Stationarity checks (ADF test)\n",
    "- Cointegration tests (Johansen)\n",
    "- VAR or VARMAX modeling\n",
    "- MAPE as evaluation metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794b73e",
   "metadata": {},
   "source": [
    "## 2. Load Data & Basic Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8896c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from statsmodels.tsa.api import VARMAX\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSVs\n",
    "train_df = pd.read_csv(\"train.csv\", parse_dates=[\"Date\"])\n",
    "store_df = pd.read_csv(\"store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb481511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data shapes\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Store shape:\", store_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview train data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d379e0b",
   "metadata": {},
   "source": [
    "## 3. Data Preparation & Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and store metadata\n",
    "df = pd.merge(train_df, store_df, on='Store', how='left')\n",
    "\n",
    "# Focus on 9 selected stores\n",
    "selected_stores = [1, 3, 8, 9, 13, 25, 29, 31, 46]\n",
    "df = df[df[\"Store\"].isin(selected_stores)]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=[\"Customers\"], inplace=True)  # Customers highly correlated with Sales and not known in advance\n",
    "\n",
    "# Fill NA in competition/opening columns\n",
    "comp_cols = [\"CompetitionDistance\", \"CompetitionOpenSinceMonth\", \"CompetitionOpenSinceYear\", \n",
    "             \"Promo2SinceWeek\", \"Promo2SinceYear\", \"PromoInterval\"]\n",
    "df[comp_cols] = df[comp_cols].fillna(0)\n",
    "\n",
    "# ➕ Feature Engineering: Promo2 Active Flag\n",
    "def is_promo2_active(row):\n",
    "    if row[\"Promo2\"] == 1 and row[\"PromoInterval\"] != 0:\n",
    "        promo_months = row[\"PromoInterval\"].split(\",\")\n",
    "        return row[\"Date\"].strftime(\"%b\") in promo_months\n",
    "    return False\n",
    "\n",
    "df[\"Promo2Active\"] = df.apply(is_promo2_active, axis=1).astype(int)\n",
    "\n",
    "# Convert Date to datetime if not already\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Sort values by Store + Date\n",
    "df.sort_values(by=[\"Store\", \"Date\"], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9340ebfa",
   "metadata": {},
   "source": [
    "## 4. Outlier Removal & Skewness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c602140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers above 99th percentile of Sales per store\n",
    "for store in selected_stores:\n",
    "    p99 = df[df.Store == store][\"Sales\"].quantile(0.99)\n",
    "    df.loc[(df.Store == store) & (df[\"Sales\"] > p99), \"Sales\"] = p99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8845b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness\n",
    "sns.histplot(df[\"Sales\"], kde=True)\n",
    "plt.title(\"Sales Distribution after Outlier Removal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d7aae",
   "metadata": {},
   "source": [
    "- Outliers at the 99th percentile can skew the time series model drastically.\n",
    "- We remove extreme sales values to ensure the stationarity test and variance structure remain valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaeea9",
   "metadata": {},
   "source": [
    "## 5. Stratified Train-Test Split (Per Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f399c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split last 6 weeks as test set (per store)\n",
    "df[\"is_test\"] = 0\n",
    "\n",
    "for store in selected_stores:\n",
    "    store_data = df[df.Store == store]\n",
    "    cutoff_date = store_data[\"Date\"].max() - pd.Timedelta(days=42)\n",
    "    df.loc[(df.Store == store) & (df[\"Date\"] > cutoff_date), \"is_test\"] = 1\n",
    "\n",
    "# Confirm split\n",
    "df[\"is_test\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2667a",
   "metadata": {},
   "source": [
    "- Since this is time series, a temporal split ensures the model is trained on past data and tested on future unseen periods.\n",
    "- By maintaining a 6-week window for each store, we simulate real-world forecasting conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f74762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
